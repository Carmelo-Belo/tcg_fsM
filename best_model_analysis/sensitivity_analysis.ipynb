{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import utils_plots as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(1980, 2022, 1) # from 1980 to 2021 included\n",
    "project_dir = '/Users/huripari/Documents/PhD/TCs_Genesis'\n",
    "fs_dir = os.path.join(project_dir, 'FS_TCG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_dict = {'NEP': ('North East Pacific', 7), \n",
    "              'NWP': ('North West Pacific', 10), \n",
    "              'NA': ('North Atlantic', 6),\n",
    "              'NI': ('North Indian', 7), \n",
    "              'SI': ('South Indian', 6), \n",
    "              'SP': ('South Pacific', 9)}\n",
    "for basin, (basin_name, n_clusters) in basin_dict.items():\n",
    "    run_names = [f'selfeat50_top20_nc{n_clusters}_nv8_nd9', f'selfeat60_top20_nc{n_clusters}_nv8_nd9', f'selfeat70_top20_nc{n_clusters}_nv8_nd9', \n",
    "                 f'selfeat75_top20_nc{n_clusters}_nv8_nd9', f'selfeat80_top20_nc{n_clusters}_nv8_nd9', f'selfeat90_top20_nc{n_clusters}_nv8_nd9']\n",
    "    col_perc = [run.split('_')[0].split('feat')[1] for run in run_names]\n",
    "    df_corr = pd.DataFrame(0.0, index=['rM', 'rY'], columns=col_perc)\n",
    "    df_mse = pd.DataFrame(0.0, index=['mseM', 'mseY'], columns=col_perc)\n",
    "    for run_name in run_names:\n",
    "        # Get the folder containing the cluster data\n",
    "        cluster_data = f'{basin}_{n_clusters}clusters'\n",
    "        target_file = 'target_1980-2022_2.5x2.5.csv'\n",
    "        cluster_data_dir = os.path.join(fs_dir, 'data', cluster_data)\n",
    "        # target\n",
    "        target_df = pd.read_csv(os.path.join(cluster_data_dir, target_file), index_col=0)\n",
    "        target_df.index = pd.to_datetime(target_df.index)\n",
    "        target_df = target_df.loc[target_df.index.year.isin(years)]\n",
    "        # Get the run info and data\n",
    "        Y_pred, Y_pred_noFS, X_test_eval, X_test_eval_noFS, mlps, mlps_noFS, shap_values_mlp = ut.runs_info(basin, run_name, project_dir)\n",
    "        # Convert list of dataframes to a single dataframe\n",
    "        X_test = pd.concat(X_test_eval)\n",
    "        X_test_noFS = pd.concat(X_test_eval_noFS)\n",
    "        Y_pred_df = pd.concat(Y_pred)\n",
    "        Y_pred_noFS_df = pd.concat(Y_pred_noFS)\n",
    "        # Annual data without trend and seasonality\n",
    "        target_df_annual = target_df.groupby(target_df.index.year).sum()\n",
    "        Y_pred_df_annual = Y_pred_df.groupby(Y_pred_df.index.year).sum()\n",
    "        Y_pred_noFS_df_annual = Y_pred_noFS_df.groupby(Y_pred_noFS_df.index.year).sum()\n",
    "        # Compute the correlation coefficient and the MSE between the predictions and the test values\n",
    "        # Monthly without trend and seasonality\n",
    "        r, _ = pearsonr(target_df['tcg'], Y_pred_df['tcg'])\n",
    "        mse = mean_squared_error(target_df['tcg'], Y_pred_df['tcg'])\n",
    "        # Annual without trend and seasonality\n",
    "        rY, _ = pearsonr(target_df_annual['tcg'], Y_pred_df_annual['tcg'])\n",
    "        mseY = mean_squared_error(target_df_annual['tcg'], Y_pred_df_annual['tcg'])\n",
    "        # Store the results\n",
    "        perc = run_name.split('_')[0].split('feat')[1]\n",
    "        df_corr.loc['rM', perc] = r\n",
    "        df_corr.loc['rY', perc] = rY\n",
    "        df_mse.loc['mseM', perc] = mse\n",
    "        df_mse.loc['mseY', perc] = mseY\n",
    "    # Plot the results\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    sns.heatmap(df_corr, annot=True, fmt=\".3f\", cmap='coolwarm', ax=ax[0])\n",
    "    ax[0].set_title('Correlation')\n",
    "    sns.heatmap(df_mse, annot=True, fmt=\".3f\", cmap='coolwarm_r', ax=ax[1])\n",
    "    ax[1].set_title('Mean squared error')\n",
    "    xtick_labels = ['50%', '60%', '70%', '75%', '80%', '90%']\n",
    "    for a in ax:\n",
    "        a.set_xticks(np.arange(len(xtick_labels), dtype=float)+0.5)\n",
    "        a.set_xticklabels(xtick_labels)\n",
    "        a.set_yticks(np.arange(2, dtype=float)+0.5)\n",
    "        a.set_yticklabels(['M', 'Y'], rotation=0)\n",
    "    fig.suptitle(f'{basin_name}')\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deseasonalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_dict = {'NEP': ('North East Pacific', 6), \n",
    "              'NWP': ('North West Pacific', 10), \n",
    "              'NA': ('North Atlantic', 10),\n",
    "              'NI': ('North Indian', 8), \n",
    "              'SI': ('South Indian', 8), \n",
    "              'SP': ('South Pacific', 9)}\n",
    "for basin, (basin_name, n_clusters) in basin_dict.items():\n",
    "    run_names = [f'selfeat50_top20_DSnc{n_clusters}_nv8_nd9', f'selfeat60_top20_DSnc{n_clusters}_nv8_nd9', f'selfeat70_top20_DSnc{n_clusters}_nv8_nd9', \n",
    "                 f'selfeat75_top20_DSnc{n_clusters}_nv8_nd9', f'selfeat80_top20_DSnc{n_clusters}_nv8_nd9', f'selfeat90_top20_DSnc{n_clusters}_nv8_nd9']\n",
    "    col_perc = [run.split('_')[0].split('feat')[1] for run in run_names]\n",
    "    df_corr = pd.DataFrame(0.0, index=['rM', 'rY'], columns=col_perc)\n",
    "    df_mse = pd.DataFrame(0.0, index=['mseM', 'mseY'], columns=col_perc)\n",
    "    for run_name in run_names:\n",
    "        # Get the folder containing the cluster data\n",
    "        cluster_data = f'{basin}_{n_clusters}clusters_deseason'\n",
    "        target_file = 'target_deseasonal_1980-2022_2.5x2.5.csv'\n",
    "        cluster_data_dir = os.path.join(fs_dir, 'data', cluster_data)\n",
    "        # target\n",
    "        target_df = pd.read_csv(os.path.join(cluster_data_dir, target_file), index_col=0)\n",
    "        target_df.index = pd.to_datetime(target_df.index)\n",
    "        target_df = target_df.loc[target_df.index.year.isin(years)]\n",
    "        # Get the run info and data\n",
    "        Y_pred, Y_pred_noFS, X_test_eval, X_test_eval_noFS, mlps, mlps_noFS, shap_values_mlp = ut.runs_info(basin, run_name, project_dir)\n",
    "        # Convert list of dataframes to a single dataframe\n",
    "        X_test = pd.concat(X_test_eval)\n",
    "        X_test_noFS = pd.concat(X_test_eval_noFS)\n",
    "        Y_pred_df = pd.concat(Y_pred)\n",
    "        Y_pred_noFS_df = pd.concat(Y_pred_noFS)\n",
    "        # Annual data without trend and seasonality\n",
    "        target_df_annual = target_df.groupby(target_df.index.year).sum()\n",
    "        Y_pred_df_annual = Y_pred_df.groupby(Y_pred_df.index.year).sum()\n",
    "        Y_pred_noFS_df_annual = Y_pred_noFS_df.groupby(Y_pred_noFS_df.index.year).sum()\n",
    "        # Compute the correlation coefficient and the MSE between the predictions and the test values\n",
    "        # Monthly without trend and seasonality\n",
    "        r, _ = pearsonr(target_df['tcg'], Y_pred_df['tcg'])\n",
    "        mse = mean_squared_error(target_df['tcg'], Y_pred_df['tcg'])\n",
    "        # Annual without trend and seasonality\n",
    "        rY, _ = pearsonr(target_df_annual['tcg'], Y_pred_df_annual['tcg'])\n",
    "        mseY = mean_squared_error(target_df_annual['tcg'], Y_pred_df_annual['tcg'])\n",
    "        # Store the results\n",
    "        perc = run_name.split('_')[0].split('feat')[1]\n",
    "        df_corr.loc['rM', perc] = r\n",
    "        df_corr.loc['rY', perc] = rY\n",
    "        df_mse.loc['mseM', perc] = mse\n",
    "        df_mse.loc['mseY', perc] = mseY\n",
    "    # Plot the results\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    sns.heatmap(df_corr, annot=True, fmt=\".3f\", cmap='coolwarm', ax=ax[0])\n",
    "    ax[0].set_title('Correlation')\n",
    "    sns.heatmap(df_mse, annot=True, fmt=\".3f\", cmap='coolwarm_r', ax=ax[1])\n",
    "    ax[1].set_title('Mean squared error')\n",
    "    xtick_labels = ['50%', '60%', '70%', '75%', '80%', '90%']\n",
    "    for a in ax:\n",
    "        a.set_xticks(np.arange(len(xtick_labels), dtype=float)+0.5)\n",
    "        a.set_xticklabels(xtick_labels)\n",
    "        a.set_yticks(np.arange(2, dtype=float)+0.5)\n",
    "        a.set_yticklabels(['M', 'Y'], rotation=0)\n",
    "    fig.suptitle(f'{basin_name}')\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detrended data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_dict = {'NEP': ('North East Pacific', 12), \n",
    "              'NWP': ('North West Pacific', 10), \n",
    "              'NA': ('North Atlantic', 12),\n",
    "              'NI': ('North Indian', 11), \n",
    "              'SI': ('South Indian', 7), \n",
    "              'SP': ('South Pacific', 10)}\n",
    "for basin, (basin_name, n_clusters) in basin_dict.items():\n",
    "    run_names = [f'selfeat50_top20_DTnc{n_clusters}_nv8_nd9', f'selfeat60_top20_DTnc{n_clusters}_nv8_nd9', f'selfeat70_top20_DTnc{n_clusters}_nv8_nd9', \n",
    "                 f'selfeat75_top20_DTnc{n_clusters}_nv8_nd9', f'selfeat80_top20_DTnc{n_clusters}_nv8_nd9', f'selfeat90_top20_DTnc{n_clusters}_nv8_nd9']\n",
    "    col_perc = [run.split('_')[0].split('feat')[1] for run in run_names]\n",
    "    df_corr = pd.DataFrame(0.0, index=['rM', 'rY'], columns=col_perc)\n",
    "    df_mse = pd.DataFrame(0.0, index=['mseM', 'mseY'], columns=col_perc)\n",
    "    for run_name in run_names:\n",
    "        # Get the folder containing the cluster data\n",
    "        cluster_data = f'{basin}_{n_clusters}clusters_detrend'\n",
    "        target_file = 'target_detrend_1980-2022_2.5x2.5.csv'\n",
    "        cluster_data_dir = os.path.join(fs_dir, 'data', cluster_data)\n",
    "        # target\n",
    "        target_df = pd.read_csv(os.path.join(cluster_data_dir, target_file), index_col=0)\n",
    "        target_df.index = pd.to_datetime(target_df.index)\n",
    "        target_df = target_df.loc[target_df.index.year.isin(years)]\n",
    "        # Get the run info and data\n",
    "        Y_pred, Y_pred_noFS, X_test_eval, X_test_eval_noFS, mlps, mlps_noFS, shap_values_mlp = ut.runs_info(basin, run_name, project_dir)\n",
    "        # Convert list of dataframes to a single dataframe\n",
    "        X_test = pd.concat(X_test_eval)\n",
    "        X_test_noFS = pd.concat(X_test_eval_noFS)\n",
    "        Y_pred_df = pd.concat(Y_pred)\n",
    "        Y_pred_noFS_df = pd.concat(Y_pred_noFS)\n",
    "        # Annual data without trend and seasonality\n",
    "        target_df_annual = target_df.groupby(target_df.index.year).sum()\n",
    "        Y_pred_df_annual = Y_pred_df.groupby(Y_pred_df.index.year).sum()\n",
    "        Y_pred_noFS_df_annual = Y_pred_noFS_df.groupby(Y_pred_noFS_df.index.year).sum()\n",
    "        # Compute the correlation coefficient and the MSE between the predictions and the test values\n",
    "        # Monthly without trend and seasonality\n",
    "        r, _ = pearsonr(target_df['tcg'], Y_pred_df['tcg'])\n",
    "        mse = mean_squared_error(target_df['tcg'], Y_pred_df['tcg'])\n",
    "        # Annual without trend and seasonality\n",
    "        rY, _ = pearsonr(target_df_annual['tcg'], Y_pred_df_annual['tcg'])\n",
    "        mseY = mean_squared_error(target_df_annual['tcg'], Y_pred_df_annual['tcg'])\n",
    "        # Store the results\n",
    "        perc = run_name.split('_')[0].split('feat')[1]\n",
    "        df_corr.loc['rM', perc] = r\n",
    "        df_corr.loc['rY', perc] = rY\n",
    "        df_mse.loc['mseM', perc] = mse\n",
    "        df_mse.loc['mseY', perc] = mseY\n",
    "    # Plot the results\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    sns.heatmap(df_corr, annot=True, fmt=\".3f\", cmap='coolwarm', ax=ax[0])\n",
    "    ax[0].set_title('Correlation')\n",
    "    sns.heatmap(df_mse, annot=True, fmt=\".3f\", cmap='coolwarm_r', ax=ax[1])\n",
    "    ax[1].set_title('Mean squared error')\n",
    "    xtick_labels = ['50%', '60%', '70%', '75%', '80%', '90%']\n",
    "    for a in ax:\n",
    "        a.set_xticks(np.arange(len(xtick_labels), dtype=float)+0.5)\n",
    "        a.set_xticklabels(xtick_labels)\n",
    "        a.set_yticks(np.arange(2, dtype=float)+0.5)\n",
    "        a.set_yticklabels(['M', 'Y'], rotation=0)\n",
    "    fig.suptitle(f'{basin_name}')\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weather",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
