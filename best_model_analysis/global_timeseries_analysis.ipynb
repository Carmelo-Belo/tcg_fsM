{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import shap\n",
    "from scipy.stats import pearsonr\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/huripari/Documents/PhD/TCs_Genesis/FS_TCG')\n",
    "import utils_results as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '/Users/huripari/Documents/PhD/TCs_Genesis'\n",
    "fs_dir = os.path.join(project_dir, 'FS_TCG')\n",
    "n_folds = 3\n",
    "years = np.arange(1980, 2022, 1) # from 1980 to 2021 included\n",
    "cluster_data_info = {'GLB': 'nc12', 'NEP': 'DSnc12', 'NWP': 'Anc10', 'NA': 'DSnc6', 'NI': 'DSnc12', 'SI':'DSnc9', 'SP': 'nc7'}\n",
    "basin_names = {'GLB': 'Global', 'NEP': 'North East Pacific',  'NWP': 'North West Pacific', 'NA': 'North Atlantic',\n",
    "              'NI': 'North Indian', 'SI': 'South Indian', 'SP': 'South Pacific'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-18 11:30:18.153939: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2025-03-18 11:30:18.153977: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2025-03-18 11:30:18.153980: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2025-03-18 11:30:18.154017: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-03-18 11:30:18.154030: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-03-18 11:30:18.507810: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "basins = ['GLB', 'NEP', 'NWP', 'NA', 'NI', 'SI', 'SP']\n",
    "for b, basin in enumerate(basins):\n",
    "    # Get the data for each basin\n",
    "    cluster_data = cluster_data_info[basin]\n",
    "    basin_name = basin_names[basin]\n",
    "    run_name = f'selfeat80_top20_{cluster_data}_nv8_nd9'\n",
    "    n_clusters = int(run_name.split('nc')[1].split('_')[0])\n",
    "    nc_string = run_name.split('_')[2]\n",
    "    # Load the file containing the time series of the predictors and of the target\n",
    "    if 'DS' in nc_string:\n",
    "        clusters_data = f'{basin}_{n_clusters}clusters_deseason'\n",
    "    elif 'A' in nc_string:\n",
    "        clusters_data = f'{basin}_{n_clusters}clusters_anomaly'\n",
    "    else:\n",
    "        clusters_data = f'{basin}_{n_clusters}clusters'\n",
    "    cluster_data_dir = os.path.join(fs_dir, 'data', f'{clusters_data}')\n",
    "    predictor_file = f'predictors_1970-2022_{n_clusters}clusters_8vars_9idxs.csv'\n",
    "    predictors_df = pd.read_csv(os.path.join(cluster_data_dir, predictor_file), index_col=0)\n",
    "    predictors_df.index = pd.to_datetime(predictors_df.index)\n",
    "    # Get the run info and data\n",
    "    run_info = ut.runs_info(basin, run_name)\n",
    "    dataset_opt = run_info[0]\n",
    "    dataset_opt_noFS = run_info[1]\n",
    "    Y_pred = run_info[2]\n",
    "    Y_pred_noFS = run_info[3]\n",
    "    Y_test = run_info[4]\n",
    "    X_test_eval = run_info[5]\n",
    "    X_test_eval_noFS = run_info[6]\n",
    "    mlps = run_info[7]\n",
    "    mlps_noFS = run_info[8]\n",
    "    perm_importance_mlp = run_info[9]\n",
    "    perm_importance_mlp_noFS = run_info[10]\n",
    "    shap_values_mlp = run_info[11]\n",
    "    shap_values_mlp_noFS = run_info[12]\n",
    "    X_test = pd.concat(X_test_eval)\n",
    "    X_test_noFS = pd.concat(X_test_eval_noFS)\n",
    "    # Load the seasonality if working with deseason data\n",
    "    if \"DS\" in nc_string:\n",
    "        cluster_data = f'{basin}_{n_clusters}clusters_deseason'\n",
    "        data_dir = os.path.join(fs_dir, 'data', cluster_data)\n",
    "        target_season = 'target_seasonality_1970-2022_2.5x2.5.csv'\n",
    "        target_season_df = pd.read_csv(os.path.join(data_dir, target_season), index_col=0)\n",
    "        target_season_df.index = pd.to_datetime(target_season_df.index)\n",
    "    # Concat the predictions and the test values\n",
    "    Y_pred_df = pd.concat(Y_pred)\n",
    "    Y_test_df = pd.concat(Y_test)\n",
    "    Y_pred_noFS_df = pd.concat(Y_pred_noFS)\n",
    "    # Create df containing the deseasonalized time series\n",
    "    Y_pred_df_noS = Y_pred_df.copy()\n",
    "    Y_test_df_noS = Y_test_df.copy()\n",
    "    Y_pred_noFS_df_noS = Y_pred_noFS_df.copy()\n",
    "    # Deseasonalize the time series\n",
    "    if \"DS\" in nc_string:\n",
    "        Y_pred_df['tcg'] = Y_pred_df['tcg'] + target_season_df.loc[Y_pred_df.index, 'seasonal']\n",
    "        Y_test_df = Y_test_df + target_season_df.loc[Y_test_df.index, 'seasonal']\n",
    "        Y_pred_noFS_df['tcg'] = Y_pred_noFS_df['tcg'] + target_season_df.loc[Y_pred_noFS_df.index, 'seasonal']\n",
    "        decomp_pred = seasonal_decompose(Y_pred_df, model='additive', period=12)\n",
    "        decomp_test = seasonal_decompose(Y_test_df, model='additive', period=12)\n",
    "        decomp_noFS = seasonal_decompose(Y_pred_noFS_df, model='additive', period=12)\n",
    "    else:\n",
    "        decomp_pred = seasonal_decompose(Y_pred_df, model='additive', period=12)\n",
    "        decomp_test = seasonal_decompose(Y_test_df, model='additive', period=12)\n",
    "        decomp_noFS = seasonal_decompose(Y_pred_noFS_df, model='additive', period=12)\n",
    "        Y_pred_df_noS['tcg'] = Y_pred_df['tcg'] - decomp_pred.seasonal\n",
    "        Y_test_df_noS = Y_test_df - decomp_test.seasonal\n",
    "        Y_pred_noFS_df_noS['tcg'] = Y_pred_noFS_df['tcg'] - decomp_noFS.seasonal\n",
    "    # Load time series of gpis\n",
    "    gpis_path = os.path.join(fs_dir, 'data', f'{basin}_2.5x2.5_gpis_time_series.csv')\n",
    "    gpis_df = pd.read_csv(gpis_path, index_col=0)\n",
    "    gpis_df.index = pd.to_datetime(gpis_df.index)\n",
    "    gpis_df = gpis_df.loc[Y_pred_df.index]\n",
    "    engpi = gpis_df['engpi']\n",
    "    ogpi = gpis_df['ogpi']\n",
    "    # Deseasonalize the time series of gpis\n",
    "    decomp_engpi = seasonal_decompose(engpi, model='additive')\n",
    "    decomp_ogpi = seasonal_decompose(ogpi, model='additive')\n",
    "    engpi_noS = engpi - decomp_engpi.seasonal\n",
    "    ogpi_noS = ogpi - decomp_ogpi.seasonal\n",
    "    # values smaller than 0 are set to 0\n",
    "    Y_pred_df.loc[Y_pred_df['tcg'] < 0, 'tcg'] = 0.0\n",
    "    Y_pred_noFS_df.loc[Y_pred_noFS_df['tcg'] < 0, 'tcg'] = 0.0\n",
    "    # Compute seasonal mean values\n",
    "    Y_pred_df_season = Y_pred_df.groupby(Y_pred_df.index.month).mean()\n",
    "    Y_test_df_season = Y_test_df.groupby(Y_test_df.index.month).mean()\n",
    "    Y_pred_noFS_df_season = Y_pred_noFS_df.groupby(Y_pred_noFS_df.index.month).mean()\n",
    "    engpi_seasonal = engpi.groupby(engpi.index.month).mean()\n",
    "    ogpi_seasonal = ogpi.groupby(ogpi.index.month).mean()\n",
    "    # Compute annual cumulative values\n",
    "    Y_pred_df_annual = Y_pred_df.groupby(Y_pred_df.index.year).sum()\n",
    "    Y_test_df_annual = Y_test_df.groupby(Y_test_df.index.year).sum()\n",
    "    Y_pred_noFS_df_annual = Y_pred_noFS_df.groupby(Y_pred_noFS_df.index.year).sum()\n",
    "    engpi_annual = engpi.groupby(engpi.index.year).sum()\n",
    "    ogpi_annual = ogpi.groupby(ogpi.index.year).sum()\n",
    "    # Remove trend from annual time series\n",
    "    Y_pred_df_noT = Y_pred_df.copy()\n",
    "    Y_test_df_noT = Y_test_df.copy()\n",
    "    Y_pred_noFS_df_noT = Y_pred_noFS_df.copy()\n",
    "    Y_pred_df_noT['tcg'] = Y_pred_df['tcg'] - decomp_pred.trend\n",
    "    Y_test_df_noT = Y_test_df - decomp_test.trend\n",
    "    Y_pred_noFS_df_noT['tcg'] = Y_pred_noFS_df['tcg'] - decomp_noFS.trend\n",
    "    engpi_noT = engpi - decomp_engpi.trend\n",
    "    ogpi_noT = ogpi - decomp_ogpi.trend\n",
    "    Y_pred_df_annual_noT = Y_pred_df_noT.groupby(Y_pred_df_noT.index.year).sum()\n",
    "    Y_test_df_annual_noT = Y_test_df_noT.groupby(Y_test_df_noT.index.year).sum()\n",
    "    Y_pred_noFS_df_annual_noT = Y_pred_noFS_df_noT.groupby(Y_pred_noFS_df_noT.index.year).sum()\n",
    "    engpi_annual_noT = engpi_noT.groupby(engpi_noT.index.year).sum()\n",
    "    ogpi_annual_noT = ogpi_noT.groupby(ogpi_noT.index.year).sum()\n",
    "    # If global store the time series, if sub-basins sum the time series\n",
    "    if basin == 'GLB':\n",
    "        Y_pred_df_GLB = Y_pred_df\n",
    "        Y_test_df_GLB = Y_test_df\n",
    "        Y_pred_noFS_df_GLB = Y_pred_noFS_df\n",
    "        engpi_GLB = engpi\n",
    "        ogpi_GLB = ogpi\n",
    "        Y_pred_df_noS_GLB = Y_pred_df_noS\n",
    "        Y_test_df_noS_GLB = Y_test_df_noS\n",
    "        Y_pred_noFS_df_noS_GLB = Y_pred_noFS_df_noS\n",
    "        engpi_noS_GLB = engpi_noS\n",
    "        ogpi_noS_GLB = ogpi_noS\n",
    "        Y_pred_df_annual_GLB = Y_pred_df_annual\n",
    "        Y_test_df_annual_GLB = Y_test_df_annual\n",
    "        Y_pred_noFS_df_annual_GLB = Y_pred_noFS_df_annual\n",
    "        engpi_annual_GLB = engpi_annual\n",
    "        ogpi_annual_GLB = ogpi_annual\n",
    "        Y_pred_df_annual_noT_GLB = Y_pred_df_annual_noT\n",
    "        Y_test_df_annual_noT_GLB = Y_test_df_annual_noT\n",
    "        Y_pred_noFS_df_annual_noT_GLB = Y_pred_noFS_df_annual_noT\n",
    "        engpi_annual_noT_GLB = engpi_annual_noT\n",
    "        ogpi_annual_noT_GLB = ogpi_annual_noT\n",
    "    elif b == 1:\n",
    "        Y_pred_df_SBS = Y_pred_df\n",
    "        Y_test_df_SBS = Y_test_df\n",
    "        Y_pred_noFS_df_SBS = Y_pred_noFS_df\n",
    "        engpi_SBS = engpi\n",
    "        ogpi_SBS = ogpi\n",
    "        Y_pred_df_noS_SBS = Y_pred_df_noS\n",
    "        Y_test_df_noS_SBS = Y_test_df_noS\n",
    "        Y_pred_noFS_df_noS_SBS = Y_pred_noFS_df_noS\n",
    "        engpi_noS_SBS = engpi_noS\n",
    "        ogpi_noS_SBS = ogpi_noS\n",
    "        Y_pred_df_annual_SBS = Y_pred_df_annual\n",
    "        Y_test_df_annual_SBS = Y_test_df_annual\n",
    "        Y_pred_noFS_df_annual_SBS = Y_pred_noFS_df_annual\n",
    "        engpi_annual_SBS = engpi_annual\n",
    "        ogpi_annual_SBS = ogpi_annual\n",
    "        Y_pred_df_annual_noT_SBS = Y_pred_df_annual_noT\n",
    "        Y_test_df_annual_noT_SBS = Y_test_df_annual_noT\n",
    "        Y_pred_noFS_df_annual_noT_SBS = Y_pred_noFS_df_annual_noT\n",
    "        engpi_annual_noT_SBS = engpi_annual_noT\n",
    "        ogpi_annual_noT_SBS = ogpi_annual_noT\n",
    "    else:\n",
    "        Y_pred_df_SBS += Y_pred_df\n",
    "        Y_test_df_SBS += Y_test_df\n",
    "        Y_pred_noFS_df_SBS += Y_pred_noFS_df\n",
    "        engpi_SBS += engpi\n",
    "        ogpi_SBS += ogpi\n",
    "        Y_pred_df_noS_SBS += Y_pred_df_noS\n",
    "        Y_test_df_noS_SBS += Y_test_df_noS\n",
    "        Y_pred_noFS_df_noS_SBS += Y_pred_noFS_df_noS\n",
    "        engpi_noS_SBS += engpi_noS\n",
    "        ogpi_noS_SBS += ogpi_noS\n",
    "        Y_pred_df_annual_SBS += Y_pred_df_annual\n",
    "        Y_test_df_annual_SBS += Y_test_df_annual\n",
    "        Y_pred_noFS_df_annual_SBS += Y_pred_noFS_df_annual\n",
    "        engpi_annual_SBS += engpi_annual\n",
    "        ogpi_annual_SBS += ogpi_annual\n",
    "        Y_pred_df_annual_noT_SBS += Y_pred_df_annual_noT\n",
    "        Y_test_df_annual_noT_SBS += Y_test_df_annual_noT\n",
    "        Y_pred_noFS_df_annual_noT_SBS += Y_pred_noFS_df_annual_noT\n",
    "        engpi_annual_noT_SBS += engpi_annual_noT\n",
    "        ogpi_annual_noT_SBS += ogpi_annual_noT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation coefficient and the MSE between the predictions and the test values\n",
    "# Monthly\n",
    "r_GLB, _ = pearsonr(Y_test_df_noS_GLB, Y_pred_df_noS_GLB['tcg']) # correllation compute with the deseasonalized values\n",
    "r_noFS_GLB, _ = pearsonr(Y_test_df_noS_GLB, Y_pred_noFS_df_noS_GLB['tcg'])\n",
    "r_engpi_GLB, _ = pearsonr(Y_test_df_noS_GLB, engpi_noS_GLB)\n",
    "r_ogpi_GLB, _ = pearsonr(Y_test_df_noS_GLB, ogpi_noS_GLB)\n",
    "mse_GLB = mean_squared_error(Y_test_df_GLB, Y_pred_df_GLB['tcg']) # mean squared error compute with the original values\n",
    "mse_noFS_GLB = mean_squared_error(Y_test_df_GLB, Y_pred_noFS_df_GLB['tcg'])\n",
    "mse_engpi_GLB = mean_squared_error(Y_test_df_GLB, engpi_GLB)\n",
    "mse_ogpi_GLB = mean_squared_error(Y_test_df_GLB, ogpi_GLB)\n",
    "# Annual\n",
    "rY, _ = pearsonr(Y_test_df_annual_noT, Y_pred_df_annual_noT['tcg']) # correlation error compute with the detrended values\n",
    "rY_noFS, _ = pearsonr(Y_test_df_annual_noT, Y_pred_noFS_df_annual_noT['tcg'])\n",
    "rY_engpi, _ = pearsonr(Y_test_df_annual_noT, engpi_annual_noT)\n",
    "rY_ogpi, _ = pearsonr(Y_test_df_annual_noT, ogpi_annual_noT)\n",
    "mseY = mean_squared_error(Y_test_df_annual, Y_pred_df_annual['tcg']) # mean squared error compute with the original values\n",
    "mseY_noFS = mean_squared_error(Y_test_df_annual, Y_pred_noFS_df_annual['tcg'])\n",
    "mseY_engpi = mean_squared_error(Y_test_df_annual, engpi_annual)\n",
    "mseY_ogpi = mean_squared_error(Y_test_df_annual, ogpi_annual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weather",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
