{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import utils_plots as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin = 'NWP'\n",
    "perc = 80\n",
    "predictors_type = 'original'\n",
    "# Set parameters for run name\n",
    "if predictors_type == 'original':\n",
    "    n_clusters_dict = {'NEP': 7, 'NWP': 10, 'NA': 6, 'NI': 7, 'SI': 6, 'SP': 9}\n",
    "    str_pt = 'nc'\n",
    "elif predictors_type == 'deseason':\n",
    "    n_clusters_dict = {'NEP': 6, 'NWP': 10, 'NA': 10, 'NI': 8, 'SI': 8, 'SP': 9}\n",
    "    str_pt = 'DSnc'\n",
    "elif predictors_type == 'detrend':\n",
    "    n_clusters_dict = {'NEP': 12, 'NWP': 10, 'NA': 12, 'NI': 11, 'SI': 7, 'SP': 10}\n",
    "    str_pt = 'DTnc'\n",
    "n_clusters = n_clusters_dict[basin]\n",
    "run_name = f'selfeat{perc}_top20_{str_pt}{n_clusters}_nv8_nd9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set years range and number of folds\n",
    "years = np.arange(1980, 2022, 1) # from 1980 to 2021 included\n",
    "n_folds = 3\n",
    "# Set directories and file paths, then load file containing predictors and target\n",
    "project_dir = '/Users/huripari/Documents/PhD/TCs_Genesis'\n",
    "# Retrieve the clusters type of data from the results folder and the target file name\n",
    "nc_string = run_name.split('_')[2]\n",
    "if \"DS\" in nc_string:\n",
    "    cluster_data = f'{basin}_{n_clusters}clusters_deseason'\n",
    "    target_file = 'target_deseasonal_1980-2022_2.5x2.5.csv'\n",
    "elif \"DT\" in nc_string:\n",
    "    cluster_data = f'{basin}_{n_clusters}clusters_detrend'\n",
    "    target_file = 'target_detrend_1980-2022_2.5x2.5.csv'\n",
    "else:\n",
    "    cluster_data = f'{basin}_{n_clusters}clusters'\n",
    "    target_file = 'target_1980-2022_2.5x2.5.csv'\n",
    "fs_dir = os.path.join(project_dir, 'FS_TCG')\n",
    "cluster_data_dir = os.path.join(fs_dir, 'data', cluster_data)\n",
    "# predictors\n",
    "predictor_file = f'predictors_1980-2022_{n_clusters}clusters_8vars_9idxs.csv'\n",
    "predictors_df = pd.read_csv(os.path.join(cluster_data_dir, predictor_file), index_col=0)\n",
    "predictors_df.index = pd.to_datetime(predictors_df.index)\n",
    "predictors_df = predictors_df.loc[predictors_df.index.year.isin(years)]\n",
    "# target\n",
    "target_df = pd.read_csv(os.path.join(cluster_data_dir, target_file), index_col=0)\n",
    "target_df.index = pd.to_datetime(target_df.index)\n",
    "target_df = target_df.loc[target_df.index.year.isin(years)]\n",
    "# gpis\n",
    "gpis_file = f'{basin}_2.5x2.5_gpis_time_series.csv'\n",
    "gpis_path = os.path.join(fs_dir, 'data', gpis_file)\n",
    "gpis_df = pd.read_csv(gpis_path, index_col=0)\n",
    "gpis_df.index = pd.to_datetime(gpis_df.index)\n",
    "gpis_df = gpis_df.loc[gpis_df.index.year.isin(years)]\n",
    "# Get the run info and data\n",
    "Y_pred, Y_pred_noFS, X_test_eval, X_test_eval_noFS, mlps, mlps_noFS, shap_values_mlp = ut.runs_info(basin, run_name, project_dir)\n",
    "# Convert list of dataframes to a single dataframe\n",
    "X_test = pd.concat(X_test_eval)\n",
    "X_test_noFS = pd.concat(X_test_eval_noFS)\n",
    "Y_pred_df = pd.concat(Y_pred)\n",
    "Y_pred_noFS_df = pd.concat(Y_pred_noFS)\n",
    "# If predictions with original data are negative, set them to 0\n",
    "if (\"DS\" not in nc_string) and (\"DT\" not in nc_string):\n",
    "    Y_pred_df[Y_pred_df < 0] = 0.0\n",
    "    Y_pred_noFS_df[Y_pred_noFS_df < 0] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time series Trajectories** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annual data without trend and seasonality\n",
    "target_df_annual = target_df.groupby(target_df.index.year).sum()\n",
    "Y_pred_df_annual = Y_pred_df.groupby(Y_pred_df.index.year).sum()\n",
    "Y_pred_noFS_df_annual = Y_pred_noFS_df.groupby(Y_pred_noFS_df.index.year).sum()\n",
    "# GPIs time series with trend and seasonality\n",
    "engpi_TS = gpis_df['engpi']\n",
    "ogpi_TS = gpis_df['ogpi']\n",
    "# GPIs time series without trend and seasonality\n",
    "decomp_engpi = STL(engpi_TS).fit()\n",
    "decomp_ogpi = STL(ogpi_TS).fit()\n",
    "if \"DS\" in nc_string:\n",
    "    engpi = engpi_TS - decomp_engpi.seasonal\n",
    "    ogpi = ogpi_TS - decomp_ogpi.seasonal\n",
    "elif \"DT\" in nc_string:\n",
    "    engpi = engpi_TS - decomp_engpi.trend\n",
    "    ogpi = ogpi_TS - decomp_ogpi.trend\n",
    "else:\n",
    "    engpi = engpi_TS\n",
    "    ogpi = ogpi_TS\n",
    "# Annual data of the GPIs\n",
    "engpi_annual = engpi.groupby(engpi.index.year).sum()\n",
    "ogpi_annual = ogpi.groupby(ogpi.index.year).sum()\n",
    "engpi_annual_TS = engpi_TS.groupby(engpi_TS.index.year).sum()\n",
    "ogpi_annual_TS = ogpi_TS.groupby(ogpi_TS.index.year).sum()\n",
    "# Compute the correlation coefficient and the MSE between the predictions and the test values\n",
    "# Monthly without trend and seasonality\n",
    "r, _ = pearsonr(target_df['tcg'], Y_pred_df['tcg'])\n",
    "r_noFS, _ = pearsonr(target_df['tcg'], Y_pred_noFS_df['tcg'])\n",
    "r_engpi, _ = pearsonr(target_df['tcg'], engpi)\n",
    "r_ogpi, _ = pearsonr(target_df['tcg'], ogpi)\n",
    "mse = mean_squared_error(target_df['tcg'], Y_pred_df['tcg'])\n",
    "mse_noFS = mean_squared_error(target_df['tcg'], Y_pred_noFS_df['tcg'])\n",
    "mse_engpi = mean_squared_error(target_df['tcg'], engpi)\n",
    "mse_ogpi = mean_squared_error(target_df['tcg'], ogpi)\n",
    "# Annual without trend and seasonality\n",
    "rY, _ = pearsonr(target_df_annual['tcg'], Y_pred_df_annual['tcg'])\n",
    "rY_noFS, _ = pearsonr(target_df_annual['tcg'], Y_pred_noFS_df_annual['tcg'])\n",
    "rY_engpi, _ = pearsonr(target_df_annual['tcg'], engpi_annual)\n",
    "rY_ogpi, _ = pearsonr(target_df_annual['tcg'], ogpi_annual)\n",
    "mseY = mean_squared_error(target_df_annual['tcg'], Y_pred_df_annual['tcg'])\n",
    "mseY_noFS = mean_squared_error(target_df_annual['tcg'], Y_pred_noFS_df_annual['tcg'])\n",
    "mseY_engpi = mean_squared_error(target_df_annual['tcg'], engpi_annual)\n",
    "mseY_ogpi = mean_squared_error(target_df_annual['tcg'], ogpi_annual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the monthly time series \n",
    "fig_ts = ut.plot_monthly_time_series(target_df['tcg'], Y_pred_df['tcg'], Y_pred_noFS_df['tcg'], engpi, ogpi, r, r_noFS, r_engpi, r_ogpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the annual time series\n",
    "fig_annual = ut.plot_annual_time_series(target_df_annual['tcg'], Y_pred_df_annual['tcg'], Y_pred_noFS_df_annual['tcg'], engpi_annual, ogpi_annual, rY, rY_noFS, rY_engpi, rY_ogpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selected Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& FS-NN & 0.216 & 0.130 & 0.003 & 0.9958 & 2.480 & 0.139 \\\\\n",
      "~ & NN & 0.226 & 0.131 & 0.005 & 0.9919 & 3.095 & 0.156 \\\\\n",
      "~ & ENGPI & 0.240 & 0.120 & 0.025 & 0.9336 & 2.267 & 0.286 \\\\\n",
      "~ & oGPI & 0.243 & 0.169 & 0.029 & 0.8415 & 2.458 & 0.186 \\\\\n"
     ]
    }
   ],
   "source": [
    "# Determine selected features according to the run_name\n",
    "if 'selfeat' in run_name:\n",
    "    perc = run_name.split('_top20')[0].split('selfeat')[1]\n",
    "    csv_path = os.path.join(fs_dir, 'results', f'selected_features_best_models_{basin}_{nc_string}.csv')\n",
    "    df_perc_sel = pd.read_csv(csv_path, index_col=0)\n",
    "    selected_features = df_perc_sel[str(perc)].dropna().to_list()\n",
    "elif 'test' in run_name:\n",
    "    experiment_filename = f'1980-2022_{n_clusters}clusters_8vars_9idxs.csv'\n",
    "    sol_filename = 'linreg_' + experiment_filename\n",
    "    output_dir = os.path.join(fs_dir, 'results', basin, run_name)\n",
    "    best_sol_path = os.path.join(output_dir, f'best_solution_{sol_filename}')\n",
    "    best_solution = pd.read_csv(best_sol_path, sep=',', header=None)\n",
    "    best_solution = best_solution.to_numpy().flatten()\n",
    "    column_names = predictors_df.columns.tolist()\n",
    "    final_sequence = best_solution[len(column_names):2*len(column_names)]\n",
    "    sequence_length = best_solution[:len(column_names)]\n",
    "    feat_sel = best_solution[2*len(column_names):]\n",
    "    variable_selection = feat_sel.astype(int)\n",
    "    time_sequences = sequence_length.astype(int)\n",
    "    time_lags = final_sequence.astype(int)\n",
    "    selected_features = []\n",
    "    for c, col in enumerate(predictors_df.columns):\n",
    "        if variable_selection[c] == 0 or time_sequences[c] == 0:\n",
    "            continue\n",
    "        for j in range(time_sequences[c]):\n",
    "            selected_features.append(str(col))\n",
    "else:\n",
    "    raise ValueError(f'Unknown run name: {run_name}')\n",
    "# Get the variables names and the selected clusters\n",
    "variables_with_cluster = [var for var in selected_features if 'cluster' in var]\n",
    "variables_without_cluster = [var for var in selected_features if 'cluster' not in var]\n",
    "variable_names_cluster = [var.split('_cluster')[0] for var in variables_with_cluster]\n",
    "variable_names_cluster = list(set(variable_names_cluster))\n",
    "variable_names_cluster.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_clusters = ut.plot_variables_clusters(basin, n_clusters, cluster_data_dir, variable_names_cluster, selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print lines for LaTEX table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'& FS-NN & {mse:.3f} & {r:.3f} & {mseS:.3f} & {rS:.4f} & {mseY:.3f} & {rY:.3f} \\\\\\\\')\n",
    "# print(f'~ & NN & {mse_noFS:.3f} & {r_noFS:.3f} & {mseS_noFS:.3f} & {rS_noFS:.4f} & {mseY_noFS:.3f} & {rY_noFS:.3f} \\\\\\\\')\n",
    "# print(f'~ & ENGPI & {mse_engpi:.3f} & {r_engpi:.3f} & {mseS_engpi:.3f} & {rS_engpi:.4f} & {mseY_engpi:.3f} & {rY_engpi:.3f} \\\\\\\\')\n",
    "# print(f'~ & oGPI & {mse_ogpi:.3f} & {r_ogpi:.3f} & {mseS_ogpi:.3f} & {rS_ogpi:.4f} & {mseY_ogpi:.3f} & {rY_ogpi:.3f} \\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SHAP values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set different parameters for following plots ##\n",
    "years_couples = []\n",
    "# Create a DataFrame with fold number corresponding to each year and also the couple of max and min years for each fold\n",
    "kfold = KFold(n_splits=n_folds)\n",
    "test_years_df = pd.DataFrame(0, index=years, columns=['fold'])\n",
    "for nf, (train_index, test_index) in enumerate(kfold.split(years)):\n",
    "    test_years_df.loc[years[test_index], 'fold'] = nf\n",
    "    Y_pred_df_annual_fold = Y_pred_df_annual.loc[years[test_index]]\n",
    "    max_fold = Y_pred_df_annual_fold['tcg'].idxmax()\n",
    "    min_fold = Y_pred_df_annual_fold['tcg'].idxmin()\n",
    "    years_couples.append((max_fold, min_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_shap = ut.plot_shap_values(shap_values_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_shap_minmax = ut.plot_minmax_shap_values(shap_values_mlp, years_couples, Y_pred, test_years_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weather",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
